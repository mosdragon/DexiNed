{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 10\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(dataset_root, partition=\"train\"):\n",
    "    \"\"\"Get the (img, annotation) pairs for the given partition.\"\"\"\n",
    "    assert (partition == \"train\") or (partition == \"test\")\n",
    "\n",
    "    if partition == \"train\":\n",
    "        BASE_IMG_DIR = os.path.join(dataset_root, \"edges/imgs/train/rgbr/aug\")\n",
    "        BASE_ANNOT_DIR = os.path.join(\n",
    "            dataset_root, \"edges/edge_maps/train/rgbr/aug\")\n",
    "\n",
    "    else:\n",
    "        BASE_IMG_DIR = os.path.join(dataset_root, \"edges/imgs/test/rgbr\")\n",
    "        BASE_ANNOT_DIR = os.path.join(\n",
    "            dataset_root, \"edges/edge_maps/test/rgbr\")\n",
    "\n",
    "    root = Path(BASE_IMG_DIR)\n",
    "    img_names = [str(fn).replace(BASE_IMG_DIR + '/', '')\n",
    "                 for fn in root.glob(\"**/*.jpg\")]\n",
    "    img_names = sorted(img_names)\n",
    "\n",
    "    img_set = [os.path.join(BASE_IMG_DIR, fn) for fn in img_names]\n",
    "    annot_set = [os.path.join(BASE_ANNOT_DIR, fn.replace(\".jpg\",\n",
    "                                                         \".png\")) for fn in img_names]\n",
    "    return (img_set, annot_set)\n",
    "\n",
    "# Helper functions for defining tf types\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(x_set, y_set, tfrecords_filename):\n",
    "    \"\"\"Writes given image/annotation pairs to the tfrecords file.\n",
    "    The function reads each image/annotation pair given filenames\n",
    "    of image and respective annotation and writes it to the tfrecord\n",
    "    file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_pairs : array of tuples (img_filepath, annotation_filepath)\n",
    "        Array of tuples of image/annotation filenames\n",
    "    tfrecords_filename : string\n",
    "        Tfrecords filename to write the image/annotation pairs\n",
    "    \"\"\"\n",
    "    writer = tf.io.TFRecordWriter(tfrecords_filename)\n",
    "\n",
    "    for img_path, annotation_path in zip(x_set, y_set):\n",
    "        img_data = tf.io.gfile.GFile(img_path, 'rb').read()\n",
    "        annotation = tf.io.gfile.GFile(annotation_path, 'rb').read()\n",
    "        \n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image': _bytes_feature(img_data),\n",
    "            'segmentation_mask': _bytes_feature(annotation)\n",
    "        }))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"Wrote tfrecord file to {tfrecords_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(trn_x, val_x, tst_x, metadata_filepath):\n",
    "    \"\"\"\n",
    "    Creates a metadata file for the training scrit to use.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"train_length\": len(trn_x),\n",
    "        \"val_length\": len(val_x),\n",
    "        \"test_length\": len(tst_x),\n",
    "    }\n",
    "    \n",
    "    with open(metadata_filepath, 'w') as wf:\n",
    "        json.dump(metadata, wf, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Record Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"./datasets/\"\n",
    "DATASET_DIR = '/home/mxs8x15/datasets/BIPED'\n",
    "\n",
    "# Test only\n",
    "(img_set_tst, annot_set_tst) = get_partition(DATASET_DIR, 'test')\n",
    "\n",
    "# All augmented samples\n",
    "(img_set_full, annot_set_full) = get_partition(DATASET_DIR, 'train')\n",
    "\n",
    "# Randomly shuffle the indices\n",
    "indices = np.arange(len(img_set_full))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Index into the original arrays in this order\n",
    "img_set_full = [img_set_full[i] for i in indices]\n",
    "annot_set_full = [annot_set_full[i] for i in indices]\n",
    "\n",
    "# Create training and validation sets\n",
    "CUTOFF = int(0.85 * len(indices))\n",
    "\n",
    "img_set_trn = img_set_full[:CUTOFF]\n",
    "annot_set_trn = annot_set_full[:CUTOFF]\n",
    "\n",
    "img_set_val = img_set_full[CUTOFF:]\n",
    "annot_set_val = annot_set_full[CUTOFF:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote tfrecord file to ./datasets/biped_trn.tfrecord\n",
      "Wrote tfrecord file to ./datasets/biped_val.tfrecord\n",
      "Wrote tfrecord file to ./datasets/biped_tst.tfrecord\n",
      "CPU times: user 17.4 s, sys: 17 s, total: 34.3 s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_tf_record(img_set_trn, annot_set_trn, os.path.join(OUT_DIR,\n",
    "                                                          \"biped_trn.tfrecord\"))\n",
    "\n",
    "create_tf_record(img_set_val, annot_set_val, os.path.join(OUT_DIR,\n",
    "                                                          \"biped_val.tfrecord\"))\n",
    "\n",
    "create_tf_record(img_set_tst, annot_set_tst, os.path.join(OUT_DIR,\n",
    "                                                          \"biped_tst.tfrecord\"))\n",
    "\n",
    "metadata_filepath = os.path.join(OUT_DIR, \"meta.json\")\n",
    "create_metadata(img_set_trn, img_set_val, img_set_tst, metadata_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
